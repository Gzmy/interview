## 简历中能想到的问题

#####说一下智能指针？

- 在C/C++程序中，由malloc和new的内存需要程序员手动使用free和delete进行释放，如果不进行释放就会造成内存泄露，已经分配出去的内存无法进行回收，随着程序运行可用内存就会越变越小，直到内存数据溢出导致程序崩溃
- 为了应对这种情况，C++中提出智能指针的思想，RAII（利用对象的生命周期来控制程序资源）用类来管理指针，类创建出来就将资源交给它管理，程序结束调用析构函数将资源释放，并且在类中重载*和->，使其可以像指针一样
- C++中有三种智能指针，第一种是C++98中的auto_ptr，他的思想是管理转移权限，一旦发生了拷贝，就把当前对象的管理权转移出去，与当前资源断开连接，但是这样就会有一个问题，我们使用的指针变量在赋值之后两个都可以使用，但是auto_ptr赋值之后前一个对象是无法使用资源的，所以这种设计很不合理
- 第二种是C++11中的unique_ptr，unique_ptr为了解决auto_ptr中的缺点，简单粗暴不允许类对象之间的拷贝和赋值，一个资源交给他也就只能由它来管理，这种设计也是非常不人性化的
- 第三种是C++11中的shared_ptr，shared_ptr内部是维护了一个资源计数器，当把一个资源赋值给另一个对象时，先断开与之前资源的联系，如果是最后一个使用这个资源的就释放，然后与新的对象共同管理一个资源，将计数器加加即可，同时这个计数器加减的过程不是线程安全的，在操作之前应该加锁
- shared_ptr中也存在一种问题，如果使用双向链表，两个智能指针分别管理node1和node2，node1的next指向node2，node2的pre指向node1，这样的话node1的next也是交给node1的智能指针来管理，引用计数就是2，如果要释放node1和node2，但是智能指针中还管理着next和pre，node1要完全释放就要释放next就是node2，node2要想完全释放就要释放pre就是node1，这样就造成谁也释放不了，就是循环引用，为了解决这种问题，就要有weak_ptr。

#####不用weak_prt如何解决循环引用问题？

- weak_ptr的构造和析构不会引起引用计数的增加或者减少,必须配合shared_ptr使用,不能单独使用
- 使用弱引用打破环状即可，自由发挥

#####说一下继承？如何解决数据的冗余

- 继承是实现代码复用的重要手段，子类继承自父类，会继承父类的成员变量以及成员函数，但是子类是共享父类里面的静态成员的，子类继承自父类有三种继承权限，是共有，保护，私有继承，如果父类的数据成员是私有的，但是以共有方式继承，那么在子类中也是不能访问父类的私有成员，继承权限与数据权限取小
- 还有一种情况是，父类中定义了数据成员，但是有子类1继承自父类，有子类2也继承，如果有孙子类继承自子类1和子类2，那么父类中的数据成员在孙子类中就会有两份，这种问题就是多重继承造成的数据冗余，为了解决这个问题，C++中使用虚拟继承，在子类继承自父类时使用virtual关键字，使用虚拟继承的子类在其对象模型中会有一个指针就是虚基表指针，这个指针指向一张表，这个表中存储着父类数据成员在本类中的偏移量，当有赋值操作时，就去这样表中拿父类的数据成员的偏移量，这样就解决了数据的二义性

#####说一下多态？

- 多态就是同一种事物在不同的情况下表现出来的不同表现，C++中有两种多态的表现
- 第一种是静态多态，静态多态就是指函数重载，在相同作用域下，函数的函数名相同，但是函数的参数列表不同，在C++编译阶段，编译器会根据函数名以及形参列表为这个函数生成一个新的函数名，在调用这个函数时，编译器根据传进来的参数来选择具体调用那个函数，这样达到多态的目的，这种多态是在编译期间完成的，所以是静态多态
- 动态多态是指在运行时才表现出来的多态，在C++中，动态多态的实现依靠与继承，在父类和子类中，子类继承自父类，父类中的函数子类中也有一份，如果不对它进行任何操作，就会造成函数隐藏，但是如果在父类中给函数名前加上virtual关键字声明是一个虚函数，用父类指针或者引用接收父类对象或者子类对象就构成多态。在程序运行时，编译器会根据传入参数的不同来决定具体调用那个函数，这就是运行时的多态
- 在有虚函数的类中，编译器在构造对象是会在对象的前四个字节（vs2017）中设置一个指针这就是虚指针，这个指针指向一张表虚基表，这个表中每个指针就是虚函数的地址。在运行时，编译器会先把对象的前四个字节取出来，找到虚基表，再根据调用的函数来决定是调用那个函数。如果在子类中对虚函数进行重写，那么就会把对象虚基表中的虚函数进行替换，以此达到运行时多态的目的。

#####new和delete的了解么？说一下区别

- new和delete是C++中的内存管理方式，通过new来申请内存，通过delete来释放内存，通过new申请出来的自定义类型的空间，会在申请成功之后调用构造函数，delete会先调用析构函数然后再来释放这段空间

- new底层是通过operator new，malloc来申请空间爱你，delete底层使用operator delete，free来释放空间。

- 区别：

  - malloc和free是函数，new和delete是操作符
  - malloc申请空间时不可以初始化，但是new可以
  - malloc申请空间时需要手动计算大小并将参数传过去，new不需要，只需要跟上类型即可，如果申请连续空间带上【】即可
  - malloc的返回值是void*，使用时需要强转，new不需要，后面就直接是类型
  - malloc申请失败时返回NULL，所以使用时必须要检查是否为空，new申请失败直接抛异常
  - malloc值负责空间的申请，不会调用构造函数，new会
  - malloc申请的空间一定在堆上，但是new不一定，因为operator new可以重载
  - new/delete比malloc/free的效率稍微第一点，因为new底层封装的是malloc

  - 只能在堆上创建对象
    - 构造，拷贝构造私有化，防止在栈上申请空间
    - 提供一个静态的函数，在堆上申请空间
  - 只能在栈上创建对象
    - 将operator new屏蔽掉即可
  - 单例模式

- 1G的地址空间能不能申请1.2G，如果使用这1.2G空间会如何？

#####C++11了解么，说一下？

- nullptr，常规的NULL只是一个0而已，如果有这种情况，有int*，和int，如果传参是NULL，就会调用整形参数，这与初衷不不符，所以C++11中定义了一个新的类型nullptr_t，使用nullptr代表空指针常量
- 可以使用初始化列表初始化
- 类型推倒：auto和基于for循环一起使用，decltype根据表达式的实际类型推演出变量定义时的类型
- final和override（强制子类进行重写）
- 委派构造函数
- 默认函数控制，使用default和delete右值引用，与移动语义相结合，std::move，完美转发
- lambda表达式，相当于一个匿名函数
- 线程库，原子性操作

#####快排的时间复杂度？介绍下快排的原理，快排为什么这么快

- 快排的最坏时间复杂度是O(N^2), 最好是O(nLogn)，先找一个基准值，经过一次遍历比基准值大的放右边，比基准值大的放左边
- 与堆排序相比较, 比较父子结点值的大小, 计算下标时在大数据中对于数组寻址也是需要一定的时间, 快速排序只需要将数组指针移动到相邻的区域即可,在快速排序中只会有大量的顺序存取数据, 而且每次的数据迁移表示它离正确的位置越来越近, 与堆排不同

#####其他的排序了解多少？

| 排序方法  | 最好时间复杂度 | 最坏时间复杂度 | 平均时间复杂度 | 空间复杂度 | 稳定性 |
| :-------: | :------------: | :------------: | :------------: | :--------: | :----: |
| 插入排序  |      O(n)      |     O(n^2)     |     o(n^2)     |    O(1)    |  稳定  |
| Shell排序 |      O(n)      |     O(n^2)     |    O(n^1.3)    |    O(1)    | 不稳定 |
| 冒泡排序  |      O(n)      |     O(n^2)     |     O(n^2)     |    O(1)    |  稳定  |
| 选择排序  |     O(n^2)     |     O(n^2)     |     O(n^2)     |    O(1)    | 不稳定 |
|  堆排序   |    O(nlogn)    |    O(nlogn)    |    O(nlogn)    |    O(1)    | 不稳定 |
|   快排    |    O(nlogn)    |     O(n^2)     |    O(nlogn)    |  O(logn)   | 不稳定 |
|   归并    |    O(nlogn)    |    O(nlogn)    |    O(nlogn)    |    O(n)    |  稳定  |

- 选择排序每次扫描一次数组只需要一次交换
- 基于比较的排序:直接插入, 冒泡, 简单选择, 希尔, 快排, 堆排
- 计数排序是属于分配式排序, 都是稳定算法

#####STL的空间配置器

- 程序中频繁使用malloc申请空间，会造成内存碎片（内部碎片和外部碎片），会影响程序效率，为了解决这个问题，STL中提出空间配置器，大于128字节使用一级空间配置器，小于128使用二级空间配置器。

  二级空间配置器使用内存池和哈希桶来解决，具体见博客

#####STL中vector的底层数据结构？扩容的时间复杂度

- 使用动态的顺序表，

- vector扩容不使用常数扩容，而是成倍扩容

  - 以成倍方法扩容的时间复杂度为常量时间
  - 一次增加固定值的实际时间复杂度是O(N)

  - 以2倍或者1.5倍方式扩容
    - 要考虑可能产生的堆空间的浪费，以2倍扩容，下一次申请的内存必然大于之前分配内存的总和，
    - 防止内存浪费，以1.5倍增长可以实现对内存的重复利用

#####红黑树的插入查询时间复杂度，与AVL树相比优越性体现在哪

- 红黑树的插入查询都是O(LOGN)，红黑树的结点不是红就是黑，根节点是黑的，叶子结点也是黑的，两个红色结点不能连在一起，最长路径不能超过最短路径的两倍，每条路径上的黑色结点都相同
- 红黑树并不追求完全平衡，只要求达到部分平衡，降低了对平衡的要求，因此也提高了性能，能够以O(LOGN)的时间复杂度来查找插入删除，任何不平衡都会在三次解决，算法的时间复杂度与AVL相同，但是统计性能比AVL更高，AVL更平衡，结构上更加直观，时间效能针对读取而言更高；维护稍慢，空间开销较大。
- 红黑树读取略逊与AVL，维护强于AVL，空间开销与AVL类似，内容极多时优于AVL，维护优于AVL，红黑树有着良好的稳定性和完整的功能，性能也不错，综合实力强

#####哈希了解嘛，如何解决哈希冲突？哈希的一致性问题？

- 哈希表是一种根据关键码去寻找值的数据结构，通过哈希函数将关键码映射的位置保存值，当然也有可能不同的哈希键映射出来的地址相同，这种情况我们称之为哈希冲突，哈希冲突的一种原因可能是哈希函数设计的不合理
- 常见的哈希函数设计原则：1、哈希函数的定义域必须要包括存储的全部关键码，2、哈希函数计算出来的地址能均匀分布在整个空间地址中，3、哈希函数的设计应该比较简单
  - 直接定制法：取关键字的某个线性函数为散列地址：Hash（key） = A * key + B;
  - 除留余数法：设散列哈希表中允许的关键字地址数为m，取一个不大于m，但最接近或者等于m的质数p作为除数，按照函数Hash（key） = key % p; 将其转换为hash地址
  - 平方取中法：取关键字的平方数的中间几位数，适用于不知道关键字的分布，而且位数又不是很大的情况
  - 折叠法：将关键字从左到右分割成位数相等的几部分，然后将这几部分求和，并按照散列表长，取后几位作为散列地址，适用于不知道关键字的分布，适合关键字位数较多的情况
  - 随机数法：选择一个随机函数，取关键字的随机函数值作为哈希散列地址，适用于关键字长度不等时的情况
  - 数学分析法：
- 处理hash冲突：
  - 闭散列（开放地址法）：当发生hash冲突时，如果hash表未被装满，说明在hash表中还有空位置，将发生冲突的hash值插入到下一个位置
    - 线性探测：从发生冲突的位置开始，依次向后进行探测，直到找到空位置为止，但是如果发生的冲突较多时，容易产生堆积，导致搜索效率降低，所以闭散列的负载因子应该严格限制在0.7-0.8以下
    - 二次探测：
  - 开散列（链地址法）：对关键码集合用散列函数计算散列地址，具有相同地址的关键码归于同一个子集合，每一个子集合称为一个桶，各个桶中的元素通过一个单链表连接起来，各个链表的表头结点存在hash表中
- 一致性hash：hash环，通过不同的算法将hash映射到顺时针的前一个环中
  - <https://my.oschina.net/zhenglingfei/blog/405622> 

##### Linux用过吗？说几个简单的命令，top？gdb？tcpdump？

- ls, cd, pwd, man, less, more, find, grep, date...
- free, stat, tcpdump, df, 

##### 进程了解吗？说一下？进程控制呢

- 通俗来讲,进程就是程序的一次动态执行，进程是CPU分配资源的最小单位，Linux操作系统创建一个进程会先创建一个进程控制块出来，在Linux中这个进程控制块就是task_struct，进程在内核中的状态以及各种信息就是通过这个结构体来描述的，调度进程就是调度PCB。
- 程序本是存在于磁盘上的，当需要执行时，会先将程序读到内存中，然后在放到寄存器中，供CPU调度执行，这时就变成了一个进程，程序运行结束，进程终止。
- task_struct中都有：<https://blog.csdn.net/Dawn_sf/article/details/78639785> 
  - 当前进程状态，是否执行，是阻塞还是就绪
  - 当前进程id，
  - sigpending位图，表示当前是否有需要处理的信号
  - 进程地址空间：区分用户空间和内核空间
  - nice：进程当前优先级，实时优先级
  - 内存管理信息，进程睡眠时间
  - 内置定时器
  - 内存缺页和交换信息
  - 文件系统信息
- 进程的三个状态
  - 运行,
  - 就绪
  - 阻塞
- 进程调度
  - 整个计算机系统中不可能只有单个的进程, 各个进程并发执行完成日常生活中的各个任务, 但是只有一个CPU, 在同一时刻就只能有一个进程被执行, 所以进程在什么时间被选中执行, 以及执行多少时间就显得非常中要, 这就是进程调度
  - 进程调度的指标
    - CPU利用率: 使CPU利用率最高
    - 系统吞吐量: 单位时间完成的进程数目
    - 周转时间: 从进程创建到终止的所经过的时间
    - 等待时间: 进程在就绪队列中等待所花费的时间总和
    - 响应时间: 时间产生到进程或者系统做出相应所经过的时间
  - 进程调度时机:
    - 正在执行的进程执行完毕, 选择新的就绪进程执行
    - 正在执行的进程调用相关的系统调用接口导致需要等待某些事件的发生或者资源可用, 从而将自己阻塞
    - 正在执行的进程主动放弃CPU, 导致自己的状态变为就绪态重新进入到就绪队列之中
    - 等待事件发生或者资源可用导致从阻塞态回到就绪态进入到就绪队列之中
    - 正在执行的进程时间片已经用完, 导致自己的状态变为就绪态进入到就绪队列中
    - 执行完系统调用之后准备返回用户进程前的时刻,
    - 就绪队列中的进程的优先级高于当前进程优先级
  - 进程调度方式
    - 可抢占式
    - 不可抢占式
  - 进程调度算法
    - 先来先服务
    - 短作业优先
    - 时间片轮转
    - 高相应比优先
    - 多级反馈队列
    - 最高优先级优先调度算法
- 进程控制
  - 进程创建-------延伸: 子进程继承了父进程的什么东西?
    - 使用fork创建一个新的进程, fork有两个返回值, 父进程返回子进程的进程id, 子进程返回0, 进程创建时子进程的PCB中大部分数据是继承自父进程, 父子进程的虚拟页表指向同一个页表项, 使用写时拷贝, 每当有进程需要写时才分配地址空间, 以提高整体效率
    - 使用vfork时保证子进程先运行
    - 使用clone创建进程----
  - 进程等待
    - 不等待会有僵尸进程, 僵尸进程是Linux下独有的一种状态, 一个进程在退出之后是不会立即释放系统资源的, 他是会等待父进程来读取自己的退出状态, 以告知父进程执行任务的结果, 如果不去管僵尸进程, 那么僵尸进程会持续霸占着系统资源不释放, 如果一个系统中有太多的僵尸进程那么这个系统就会严重影响系统的系能
    - 使用wait或者waitpid函数进行等待, wait函数是阻塞等待, waitpid可以设置非阻塞式
    - 或者使用信号, 在每个子进程退出之前, 会给父进程发送一个SIGCHILD信号, 可以在父进程中注册一个信号处理函数, 等到有信号到来时调用wait或者waitpid函数
  - 进程终止
    - 可以使用exit
    - 或者使用_exit, 这个函数不会清理当前进程状态, 直接退出
  - 进程替换
    - 使用fork+exec进行进程替换

##### 进程间通信的几种方式? 共享内存为什么这么快? 静态库和动态库说一下

- 进程间通信的方式
  - 使用文件通信
  - 共享内存
  - 信号量
  - 消息队列
  - 管道
    - 匿名管道用于具有亲缘关系的进程通信
    - 命名管道
  - 可以使用Socket通信
- 共享内存为什么是最快的进程间通信的方式
  - 共享内存映射到进程的地址空间, 进程间的数据传递不在涉及到内核, 进程不在进入内核态传递彼此的数据
- 静态库和动态库
  - 静态库:`.a`
    - 程序将库中的所有被使用的代码都复制到最终的可执行文件中, 导致最终生成的可执行文件体积较大, 但是运行起来相对来说比较快一点, 会占用磁盘和内存空间
  - 动态库:`.so`
    - 与共享库连接的可执行文件只需要包含它所需要的函数引用表, 而不是所有函数的执行代码, 只有在执行时才将哪些函数拷贝到内存中, 使得可执行文件的体积比较小, 节省磁盘空间, 更近一步, 操作系统使用虚拟地址空间, 只将一份共享库驻留在内存中, 这样可以供多个进程来使用, 节约了内存, 不过运行时连接库会消耗一定的时间, 执行速度会相对慢一点
  - 静态库时牺牲空间换时间, 动态库是牺牲时间换空间

#####页表? 文件系统? 知道是怎么实现的?

##### 进程的虚拟地址空间?

##### 说一下线程, 线程共享哪些数据

##### 线程安全?如何解决?死锁相关

##### 读写锁?自旋锁?生产者消费者模型?

##### 信号的处理流程

- 信号递达: 信号实际执行的处理动作
- 信号未决: 从产生到抵达之间的状态

##### HTTP的长连接和短连接, header里面都有什么

- 短连接: 在HTTP/1.0中默认使用短连接
  - 客户端每进行一次HTTP操作, 就建立一次连接, 任务结束就中断连接, 当客户端浏览器访问的某个web页面中包含其他的web资源(css, 图像资源), 就重新建立一个HTTP会话
- 长连接: 在HTTP/1.1中默认使用
  - 使用长连接时,会在请求头中加入 `Connection: keep-alive`
  - 当一个网页打开完成之后, 客户端和服务器之间用于传输的TCP连接是不会关闭的, 客户端再次访问这个服务器, 会继续使用之前已经存在的连接, keep-alive不会永久保持, 他有一个保持连接的时间, 实现长连接需要客户端和服务器都支持
- 长连接省去较多的TCP建立和关闭操作, 减少浪费, 节约时间, 对于资源请求比较频繁的客户比较适用于长连接, 随着client的连接越来越多, server早晚会扛不住, 这时候server会采取一些措施, 比如关闭一些长时间没有读写事件发生的连接, 可以避免恶意连接导致server端受损
- 短连接对于服务器来说管理比较简单, 存放的都是有用的连接, 但是客户请求频繁, 在TCP的建立和关闭操作上将会浪费时间和带宽
- header里面的内容
  - allow:服务器支持哪些请求方法
  - content-length: 表示正文长度
  - content-type: 属于什么类型的文档
  - date: 当前的时间
  - host:请求的主机是在哪个主机的那个端口
  - user-agent:声明用户的操作系统和版本
  - referer:当前页面是从哪个页面跳转而来
  - location:搭配30x使用, 告诉用户将要去哪个页面
  - cookie:用于在客户端存储少量信息, 实现会话功能
- 状态码
  - 100: 继续, 客户端继续请求
  - 101: 切换协议
  - 200: 请求成功
  - 202:已经接收请求但是没有处理完
  - 204:服务器处理成功, 没有返回内容
  - 301: 永久性重定向
  - 302: 临时性重定向
  - 307: 与302相同, 但是使用GET请求
  - 400: 请求语法错误, 服务器无法理解
  - 401: 要求用户的身份认证
  - 403: 服务器拒绝执行
  - 404: 请求资源未找到
  - 500: 服务器内部错误
  - 503: 系统维护, 暂时无法处理客户端请求
- 



